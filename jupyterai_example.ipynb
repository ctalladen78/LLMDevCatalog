{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uHH3oN8Y48Ig",
      "metadata": {
        "id": "uHH3oN8Y48Ig"
      },
      "outputs": [],
      "source": [
        "https://github.com/jupyterlab/jupyter-ai/blob/main/examples/code.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7c709c4-0dbe-4f82-8ee6-f4cf2fd55b68",
      "metadata": {
        "id": "c7c709c4-0dbe-4f82-8ee6-f4cf2fd55b68",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%reload_ext jupyter_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f69abe97-654c-4e4a-8d18-575deca9c935",
      "metadata": {
        "id": "f69abe97-654c-4e4a-8d18-575deca9c935",
        "tags": []
      },
      "outputs": [],
      "source": [
        "%%ai chatgpt --format code\n",
        "A program that asks me for my name and then greets me by my name, in Polish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a832d3be-7a0b-49bc-aaf6-da8a32a89285",
      "metadata": {
        "id": "a832d3be-7a0b-49bc-aaf6-da8a32a89285",
        "outputId": "98717a63-35a4-4832-cd11-056f3cbfbda9",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jak masz na imię?  foo\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cześć foo!\n"
          ]
        }
      ],
      "source": [
        "name = input(\"Jak masz na imię? \")\n",
        "print(\"Cześć \" + name + \"!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e187e37-9abd-4ed2-9959-fb3acdb3acfe",
      "metadata": {
        "id": "7e187e37-9abd-4ed2-9959-fb3acdb3acfe"
      },
      "outputs": [],
      "source": [
        "%%ai chatgpt --format code\n",
        "A function that computes the lowest common multiples of two integers, and a function that runs 5 test cases of the lowest common multiple function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "555662c1-f576-4786-8dda-51ebe48c1d75",
      "metadata": {
        "id": "555662c1-f576-4786-8dda-51ebe48c1d75",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def lcm(x, y):\n",
        "    if x > y:\n",
        "        greater = x\n",
        "    else:\n",
        "        greater = y\n",
        "\n",
        "    while True:\n",
        "        if (greater % x == 0) and (greater % y == 0):\n",
        "            lcm = greater\n",
        "            break\n",
        "        greater += 1\n",
        "\n",
        "    return lcm\n",
        "\n",
        "def test_lcm():\n",
        "    assert lcm(3, 5) == 15\n",
        "    assert lcm(7, 9) == 63\n",
        "    assert lcm(18, 24) == 72\n",
        "    assert lcm(10, 15) == 30\n",
        "    assert lcm(12, 16) == 48\n",
        "\n",
        "test_lcm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260f7bfa",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "25928551",
      "metadata": {},
      "source": [
        "https://github.com/jupyterlab/jupyter-ai/blob/main/examples/commands.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "710c3aa3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model alias\n",
        "# Using the syntax %ai register NAME TARGET, you can create a new alias to an \n",
        "# existing alias's target. The target must be specified using the full \n",
        "# provider:model syntax. You cannot create an alias to another alias.\n",
        "\n",
        "%ai register mychat openai-chat:gpt-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9978c08c-c0da-49dd-9e01-3b9d8c9e1a5e",
      "metadata": {
        "id": "9978c08c-c0da-49dd-9e01-3b9d8c9e1a5e"
      },
      "outputs": [],
      "source": [
        "%reload_ext jupyter_ai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be93695",
      "metadata": {},
      "outputs": [],
      "source": [
        "%ai help\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcb2ca5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "%ai list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dcd5b78",
      "metadata": {},
      "outputs": [],
      "source": [
        "%ai list openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c738f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom chains\n",
        "# You can define a LangChain chain in a local variable and use that as the target \n",
        "# in a magic %ai register command.\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "# Run the chain only specifying the input variable.\n",
        "print(chain.run(\"colorful socks\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bd227b21",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c10197",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "af56c845",
      "metadata": {},
      "source": [
        "### Experimenting with different HF Hub models\n",
        "We can call models on HuggingFace Hub that return images:\n",
        "format image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3512747",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai huggingface_hub:stabilityai/stable-diffusion-2-1 --format image\n",
        "It's an astronaut with a boombox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aec9031e",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai huggingface_hub:runwayml/stable-diffusion-v1-5 --format image\n",
        "It's an astronaut with a boombox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3202b74",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai huggingface_hub:hakurei/waifu-diffusion --format image\n",
        "It's an astronaut with a boombox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5326753",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai anthropic:claude-v1.2\n",
        "Write a poem about C++."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6001a366",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai huggingface_hub:google/flan-t5-xl\n",
        "What is the capital of New York state?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b11d0355",
      "metadata": {},
      "source": [
        "* format html\n",
        "* format math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a0f1c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai anthropic:claude-v1.2 -f html\n",
        "Create a square using SVG with a black border and white fill. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b344f8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%ai chatgpt -f math\n",
        "Generate the 2D heat equation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1377f92e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c84527b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ad38791",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5bdb4df",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "127cd220",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b42c10f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
